{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cd30ee",
   "metadata": {
    "id": "e19a72b7-aaca-4f6b-b688-0a05103dd1a7",
    "outputId": "35210dc4-0d63-4f66-b226-0e1e03468464",
    "papermill": {
     "duration": 11.125415,
     "end_time": "2025-04-05T01:13:27.754232",
     "exception": false,
     "start_time": "2025-04-05T01:13:16.628817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0.1 4.50.3 0.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sentencepiece\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(pyarrow.__version__, transformers.__version__, sentencepiece.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d49711",
   "metadata": {
    "id": "9552276b-7647-4701-b3a5-ff1876327a38",
    "outputId": "7073f601-2e06-431c-fe70-d15896cac076",
    "papermill": {
     "duration": 0.069491,
     "end_time": "2025-04-05T01:13:27.837274",
     "exception": false,
     "start_time": "2025-04-05T01:13:27.767783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30522  # Example vocab size (from tokenizer)\n",
    "embedding_dim = 768  # Embedding dimension\n",
    "hidden_dim = 512  # Hidden dimension for GRU\n",
    "MAX_LENGTH = 50  # Define max length for your sequences\n",
    "SOS_token = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe6f44d",
   "metadata": {
    "id": "22036d3c-e1f7-44b5-9395-6346e7ec76c3",
    "papermill": {
     "duration": 0.58397,
     "end_time": "2025-04-05T01:13:28.434357",
     "exception": false,
     "start_time": "2025-04-05T01:13:27.850387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset(split):\n",
    "    return pd.read_parquet(f\"iwslt2015-en-vi/{split}-00000-of-00001.parquet\")\n",
    "\n",
    "train = read_dataset(\"train\")\n",
    "validation = read_dataset(\"validation\")\n",
    "test = read_dataset(\"test\")\n",
    "\n",
    "# full_train = pd.concat([train, validation], ignore_index=True)\n",
    "\n",
    "# train.shape, validation.shape, full_train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf1f16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:28.461096Z",
     "iopub.status.busy": "2025-04-05T01:13:28.460801Z",
     "iopub.status.idle": "2025-04-05T01:13:28.466732Z",
     "shell.execute_reply": "2025-04-05T01:13:28.465892Z"
    },
    "id": "a5e15ca1-71e7-44ed-ac26-2e0b96c028fd",
    "papermill": {
     "duration": 0.02062,
     "end_time": "2025-04-05T01:13:28.468148",
     "exception": false,
     "start_time": "2025-04-05T01:13:28.447528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, source_texts, target_texts, tokenizer, max_len=50):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_text = self.source_texts[idx]\n",
    "        target_text = self.target_texts[idx]\n",
    "\n",
    "        # Tokenize source text and target text with padding\n",
    "        source_encoding = self.tokenizer(\n",
    "            source_text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=False\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',  # Pad to max_len\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=False\n",
    "        )\n",
    "\n",
    "        # Move the tensors to the device (cuda or cpu)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Return tokenized input and target sequences moved to the proper device\n",
    "        return {\n",
    "            'source_input_ids': source_encoding['input_ids'].squeeze(0).to(device),\n",
    "            'target_input_ids': target_encoding['input_ids'].squeeze(0).to(device),\n",
    "            'target_labels': target_encoding['input_ids'].squeeze(0).to(device)  # For training targets\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114cd71",
   "metadata": {
    "id": "7f2867ba-30df-4261-b9b5-f89de93f490b",
    "papermill": {
     "duration": 0.01254,
     "end_time": "2025-04-05T01:13:28.493538",
     "exception": false,
     "start_time": "2025-04-05T01:13:28.480998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bidirectional RNNs (Recurrent Newral Networks)\n",
    "\n",
    "Process the input sequence in two directions:\n",
    "\n",
    "    1. Forward direction (l-r): as normal RNN works\n",
    "    \n",
    "    2. Backward direction (r-l): the sequence is processed from the last token and going back to the beginning\n",
    "\n",
    "#### h_t = [h_t^f, h_t^b]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6550b01c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:28.519761Z",
     "iopub.status.busy": "2025-04-05T01:13:28.519446Z",
     "iopub.status.idle": "2025-04-05T01:13:28.526051Z",
     "shell.execute_reply": "2025-04-05T01:13:28.525262Z"
    },
    "id": "db2dd22e-7faa-4692-828f-109513e74721",
    "papermill": {
     "duration": 0.021261,
     "end_time": "2025-04-05T01:13:28.527377",
     "exception": false,
     "start_time": "2025-04-05T01:13:28.506116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers=2, dropout_p=0.1, bidirectional=True):\n",
    "        \"\"\"\n",
    "        Encoder GRU with optional bidirectional support.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size (int): The size of the vocabulary for the input text.\n",
    "        - embedding_dim (int): The size of the embedding vector.\n",
    "        - hidden_dim (int): The number of hidden units in the GRU layer.\n",
    "        - num_layers (int): The number of layers in the GRU. Default is 2.\n",
    "        - dropout_p (float): Dropout rate for regularization.\n",
    "        - bidirectional (bool): Whether to use a bidirectional GRU. Default is True.\n",
    "\n",
    "        Shapes:\n",
    "        - embedding.shape = [batch_size, seq_len, embedding_dim]\n",
    "        - gru_out.shape = [batch_size, seq_len, hidden_dim * num_directions (2 if bidirectional else 1)]\n",
    "        - hidden.shape (before bidirectional) = [num_layers * num_directions, batch_size, hidden_dim]\n",
    "        - If bidirectional: hidden.shape = [batch_size, hidden_dim * 2] (concat two directions)\n",
    "        - If not bidirectional: hidden.shape = [batch_size, hidden_dim] (last hidden state only)\n",
    "        - hidden.shape (after fc): [batch_size, hidden_dim] (optional if having bidirectional)\n",
    "        \"\"\"\n",
    "\n",
    "        super(EncoderGRU, self).__init__()\n",
    "\n",
    "        # Embedding layer: Converts word indices to dense vectors of size embedding_dim\n",
    "        # Input shape: [batch_size, seq_len] -> Output shape: [batch_size, seq_len, embedding_dim]:Reason\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # GRU Layer (with optional bidirectionality and dropout)\n",
    "        # Input shape: [batch_size, seq_len, embedding_dim] -> Output shape: [batch_size, seq_len, hidden_dim * num_directions] \n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, dropout=dropout_p, bidirectional=bidirectional)\n",
    "\n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Fully connected layer to adjust hidden state size (optional)\n",
    "        # If bidirectional, input size is hidden_dim * 2, else hidden_dim\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the Encoder GRU.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): The input tensor of shape [batch_size, seq_len], where each element is a token ID.\n",
    "\n",
    "        Returns:\n",
    "        - gru_out (Tensor): The output of the GRU for each time step, shape [batch_size, seq_len, hidden_dim * num_directions]\n",
    "        - hidden (Tensor): The final hidden state after the GRU, shape [batch_size, hidden_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # Pass input through embedding layer and apply dropout\n",
    "        embedded = self.dropout(self.embedding(x))  # Shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Pass the embedded input through the GRU\n",
    "        gru_out, hidden = self.gru(embedded)  # gru_out: [batch_size, seq_len, hidden_dim * num_directions]\n",
    "\n",
    "        # If the GRU is bidirectional, concatenate the final hidden states from both directions\n",
    "        if self.gru.bidirectional:\n",
    "            # Hidden state shape before bidirectional handling: [num_layers * 2, batch_size, hidden_dim]\n",
    "            # We concatenate the last hidden state from the forward and backward directions\n",
    "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # Shape: [batch_size, hidden_dim * 2]\n",
    "        else:\n",
    "            # If not bidirectional, just take the final hidden state (last time step)\n",
    "            hidden = hidden[-1,:,:]  # Shape: [batch_size, hidden_dim]\n",
    "\n",
    "        # Optionally apply a fully connected layer to the final hidden state (for dimensionality adjustment)\n",
    "        hidden = self.fc(hidden)  # Shape: [batch_size, hidden_dim]\n",
    "\n",
    "        # Optionally apply a fully connected layer to the GRU output (to project it to another space)\n",
    "        # You can decide if you need this, but it can help adjust the shape if needed\n",
    "        gru_out = self.fc(gru_out)  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        return gru_out, hidden  # Return the GRU outputs and the final hidden state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a715450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:28.553004Z",
     "iopub.status.busy": "2025-04-05T01:13:28.552791Z",
     "iopub.status.idle": "2025-04-05T01:13:28.555735Z",
     "shell.execute_reply": "2025-04-05T01:13:28.555118Z"
    },
    "id": "bca1dc29-a291-4e23-a80d-bc745c552e90",
    "papermill": {
     "duration": 0.017123,
     "end_time": "2025-04-05T01:13:28.556901",
     "exception": false,
     "start_time": "2025-04-05T01:13:28.539778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# question 1: what output size should I use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158d38e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:28.583695Z",
     "iopub.status.busy": "2025-04-05T01:13:28.583471Z",
     "iopub.status.idle": "2025-04-05T01:13:30.113907Z",
     "shell.execute_reply": "2025-04-05T01:13:30.112989Z"
    },
    "id": "639d36bd-4adb-4731-b95e-69416ff3746f",
    "outputId": "20806d16-cdb2-4378-b39e-2b9fa97ef5cb",
    "papermill": {
     "duration": 1.546139,
     "end_time": "2025-04-05T01:13:30.115578",
     "exception": false,
     "start_time": "2025-04-05T01:13:28.569439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665a850464f45f49320374058c65fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a6705bac124e099bd2fc737b4ec738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299b105e54e84a95847a32da935567e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df78b2c0e86041cea236171e20777275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')  # Change to your tokenizer\n",
    "\n",
    "def get_dataloader(data, batch_size=64, shuffle=True):\n",
    "    # Create Dataset and DataLoader\n",
    "    dataset = Seq2SeqDataset(data[\"en\"], data[\"vi\"], tokenizer)\n",
    "    # Use a more typical batch size (adjust based on your memory constraints)\n",
    "    return DataLoader(dataset, batch_size, shuffle)\n",
    "\n",
    "train_loader = get_dataloader(train)\n",
    "# dir(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cec22fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:30.147601Z",
     "iopub.status.busy": "2025-04-05T01:13:30.147318Z",
     "iopub.status.idle": "2025-04-05T01:13:45.234880Z",
     "shell.execute_reply": "2025-04-05T01:13:45.234065Z"
    },
    "id": "2bca2f3e-c231-4eef-93d6-de01f26d75bf",
    "outputId": "4dc6cf2a-8d96-4986-b993-0a1aaeb5fb33",
    "papermill": {
     "duration": 15.10481,
     "end_time": "2025-04-05T01:13:45.236203",
     "exception": false,
     "start_time": "2025-04-05T01:13:30.131393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 30522\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b32ffbf490442da92bb82409afebd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(EncoderGRU(\n",
       "   (embedding): Embedding(30522, 768)\n",
       "   (gru): GRU(768, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       " ),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "vocab_size = len(tokenizer)  # 30522 for BERT's vocab size\n",
    "print(f\"Tokenizer vocab size: {vocab_size}\")\n",
    "\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "embedding_dim = model.config.hidden_size\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "\n",
    "# Now, ensure your model has the correct vocab_size in the embedding layer\n",
    "encoder = EncoderGRU(vocab_size, embedding_dim=embedding_dim, hidden_dim=512)\n",
    "encoder, next(encoder.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77fd20e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.265013Z",
     "iopub.status.busy": "2025-04-05T01:13:45.264510Z",
     "iopub.status.idle": "2025-04-05T01:13:45.565997Z",
     "shell.execute_reply": "2025-04-05T01:13:45.565195Z"
    },
    "id": "NEZ3F5Y2PD-7",
    "outputId": "46d8fc71-bb13-4839-b7f3-b16b4f2e617d",
    "papermill": {
     "duration": 0.316882,
     "end_time": "2025-04-05T01:13:45.567331",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.250449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(device)\n",
    "next(encoder.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24f5f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.595473Z",
     "iopub.status.busy": "2025-04-05T01:13:45.595192Z",
     "iopub.status.idle": "2025-04-05T01:13:45.597972Z",
     "shell.execute_reply": "2025-04-05T01:13:45.597366Z"
    },
    "id": "40a27cfc-9528-4c26-9137-b8b4b9cb2983",
    "papermill": {
     "duration": 0.018075,
     "end_time": "2025-04-05T01:13:45.599189",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.581114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     batch\n",
    "#     first_batch = batch[\"source_input_ids\"]\n",
    "#     break\n",
    "# print(first_batch.shape)\n",
    "# gru_out, hidden = encoder(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ee95ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.626761Z",
     "iopub.status.busy": "2025-04-05T01:13:45.626540Z",
     "iopub.status.idle": "2025-04-05T01:13:45.629262Z",
     "shell.execute_reply": "2025-04-05T01:13:45.628652Z"
    },
    "id": "3a12d73d-6be0-4159-b33c-19a6f7946417",
    "papermill": {
     "duration": 0.017917,
     "end_time": "2025-04-05T01:13:45.630491",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.612574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gru_out.shape, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c4c70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.657762Z",
     "iopub.status.busy": "2025-04-05T01:13:45.657533Z",
     "iopub.status.idle": "2025-04-05T01:13:45.662472Z",
     "shell.execute_reply": "2025-04-05T01:13:45.661809Z"
    },
    "id": "40927091-7aaf-4fdf-ab7d-2170e436cb62",
    "papermill": {
     "duration": 0.020045,
     "end_time": "2025-04-05T01:13:45.663738",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.643693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        \"\"\"\n",
    "        Initialize the Luong Attention mechanism.\n",
    "\n",
    "        Parameters:\n",
    "        - hidden_dim (int): The dimension of the hidden states from the encoder and decoder.\n",
    "        \"\"\"\n",
    "        super(LuongAttention, self).__init__()\n",
    "        # Attention layer that learns a linear transformation for the decoder hidden state\n",
    "        self.attn = nn.Linear(hidden_dim, hidden_dim)  # Projection layer for the decoder hidden state\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        \"\"\"\n",
    "        Forward pass for the attention mechanism.\n",
    "\n",
    "        Args:\n",
    "        - encoder_outputs (Tensor): The encoder outputs of shape [batch_size, seq_len, hidden_dim * 2]\n",
    "        - decoder_hidden (Tensor): The decoder's current hidden state of shape [batch_size, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "        - context_vector (Tensor): The weighted sum of encoder outputs, shaped [batch_size, hidden_dim * 2]\n",
    "        - attention_weights (Tensor): The attention weights for each encoder output, shaped [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        seq_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # Project decoder hidden state into the same dimensionality as the encoder outputs\n",
    "        query = self.attn(decoder_hidden).unsqueeze(1)  # Shape: [batch_size, 1, hidden_dim]\n",
    "\n",
    "        # Compute attention scores by performing a dot-product between the query (decoder hidden state)\n",
    "        # and the encoder outputs (keys). This results in energy scores.\n",
    "        energy = torch.bmm(query, encoder_outputs.transpose(1, 2))  # Shape: [batch_size, 1, seq_len]\n",
    "\n",
    "        # Apply softmax to compute the attention weights, normalizing them over the sequence length.\n",
    "        attention_weights = torch.softmax(energy.squeeze(1), dim=1)  # Shape: [batch_size, seq_len]\n",
    "\n",
    "        # Compute the context vector as the weighted sum of encoder outputs based on the attention weights\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)  # Shape: [batch_size, 1, hidden_dim * 2]\n",
    "        context_vector = context_vector.squeeze(1)  # Shape: [batch_size, hidden_dim * 2]\n",
    "\n",
    "        # Return the context vector and attention weights\n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b150ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.691195Z",
     "iopub.status.busy": "2025-04-05T01:13:45.690947Z",
     "iopub.status.idle": "2025-04-05T01:13:45.696320Z",
     "shell.execute_reply": "2025-04-05T01:13:45.695657Z"
    },
    "id": "b68382c8-4f2a-43c7-a1fc-701d80f1790b",
    "papermill": {
     "duration": 0.020566,
     "end_time": "2025-04-05T01:13:45.697589",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.677023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        \"\"\"\n",
    "        Initialize the Bahdanau Attention mechanism.\n",
    "\n",
    "        Parameters:\n",
    "        - hidden_size (int): The dimension of the hidden state in the encoder and decoder.\n",
    "        \"\"\"\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "\n",
    "        # Linear transformations for the query (decoder hidden state) and keys (encoder outputs)\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)  # For the query (decoder hidden state)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)  # For the keys (encoder outputs)\n",
    "        self.Va = nn.Linear(hidden_size, 1)            # Final layer for the attention score\n",
    "\n",
    "    def forward(self, keys, query):\n",
    "        \"\"\"\n",
    "        Compute the attention scores based on the decoder hidden state (query) and encoder outputs (keys).\n",
    "\n",
    "        Args:\n",
    "        - query (Tensor): The decoder hidden state of shape [batch_size, hidden_size].\n",
    "        - keys (Tensor): The encoder outputs of shape [batch_size, seq_len, hidden_size].\n",
    "\n",
    "        Returns:\n",
    "        - context_vector (Tensor): The weighted sum of encoder outputs, shape [batch_size, hidden_size].\n",
    "        - attention_weights (Tensor): The attention weights for each encoder output, shape [batch_size, seq_len].\n",
    "        \"\"\"\n",
    "\n",
    "        # Transform the query (decoder hidden state) and keys (encoder outputs)\n",
    "        query_transformed = self.Wa(query).unsqueeze(1)  # Shape: [batch_size, 1, hidden_size]\n",
    "        keys_transformed = self.Ua(keys)  # Shape: [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        # Compute the attention scores using the transformed query and keys\n",
    "        # This adds the query and keys, passes through a tanh activation, and then a final linear layer\n",
    "        scores = self.Va(torch.tanh(query_transformed + keys_transformed))  # Shape: [batch_size, seq_len, 1]\n",
    "\n",
    "        # Squeeze the last dimension to get attention scores of shape [batch_size, seq_len]\n",
    "        scores = scores.squeeze(2)  # Shape: [batch_size, seq_len]\n",
    "\n",
    "        # Apply softmax to get attention weights, normalizing them over the sequence length (seq_len)\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "\n",
    "        # Compute the context vector as the weighted sum of encoder outputs based on attention weights\n",
    "        # Attention weights are multiplied with the encoder outputs\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), keys)  # Shape: [batch_size, 1, hidden_size]\n",
    "\n",
    "        # Remove the extra dimension to get the final context vector shape: [batch_size, hidden_size]\n",
    "        context_vector = context_vector.squeeze(1)  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "        # Return the context vector and the attention weights\n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fabc91a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.725110Z",
     "iopub.status.busy": "2025-04-05T01:13:45.724878Z",
     "iopub.status.idle": "2025-04-05T01:13:45.728790Z",
     "shell.execute_reply": "2025-04-05T01:13:45.728139Z"
    },
    "id": "059f7eb6-e2c2-4fb2-8c84-17c641449236",
    "papermill": {
     "duration": 0.019045,
     "end_time": "2025-04-05T01:13:45.730032",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.710987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AttnDecoderGRU(nn.Module):\n",
    "#     def __init__(self, hidden_size, vocab_size, attention_type=\"Bahdanau\", dropout_p=0.1, num_layers=2, bidirectional=False):\n",
    "#         super(AttnDecoderGRU, self).__init__()\n",
    "\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.bidirectional = bidirectional\n",
    "\n",
    "#         # Embedding layer for target tokens\n",
    "#         self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "#         # Attention mechanism (Bahdanau or Luong)\n",
    "#         if attention_type == 'Luong':\n",
    "#             self.attention = LuongAttention(hidden_size)\n",
    "#         elif attention_type == 'Bahdanau':\n",
    "#             self.attention = BahdanauAttention(hidden_size)\n",
    "#         else:\n",
    "#             raise ValueError(\"Unknown attention type\")\n",
    "\n",
    "#         # GRU for generating output sequence\n",
    "#         self.gru = nn.GRU(hidden_size * 2, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_p, bidirectional=bidirectional)\n",
    "\n",
    "\n",
    "#         # self.gru = nn.GRU(hidden_size + hidden_size * 2, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_p, bidirectional=bidirectional)\n",
    "\n",
    "#         # Linear layer to project GRU output to vocab size (adjusted for bidirectional GRU)\n",
    "#         # If bidirectional GRU, hidden_size * 2 (1024) should be used\n",
    "#         self.out = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, vocab_size)\n",
    "\n",
    "#         # Dropout layer for regularization\n",
    "#         self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "#         self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, hidden_dim)\n",
    "\n",
    "#     def forward(self, decoder_input, decoder_hidden, encoder_outputs, target_tensor=None):\n",
    "#         batch_size = encoder_outputs.size(0)\n",
    "#         device = encoder_outputs.device\n",
    "\n",
    "#         # Store outputs and attention weights for visualization\n",
    "#         decoder_outputs = []\n",
    "#         attentions = []\n",
    "\n",
    "#         # Initialize the first decoder input (SOS token)\n",
    "#         decoder_input = torch.full((batch_size, 1), SOS_token, dtype=torch.long, device=device)\n",
    "\n",
    "#         for i in range(MAX_LENGTH):\n",
    "#             print(f\"Decoder hidden shape at timestep {i}:\", decoder_hidden.shape)\n",
    "#             print(encoder_outputs.shape)\n",
    "\n",
    "#             # Compute the context vector and attention weights\n",
    "#             context, attn_weights = self.attention(encoder_outputs, decoder_hidden)\n",
    "#             print(\"Context shape\", context.shape)\n",
    "#             # Embed the current decoder input token\n",
    "#             embedded = self.embedding(decoder_input)\n",
    "#             print(\"Decoder_input shape:\", decoder_input.shape)\n",
    "#             embedded = self.dropout(embedded)\n",
    "\n",
    "#             context = context.unsqueeze(1)  # Adding sequence dimension to context\n",
    "#             print(\"E C\", embedded.shape, context.shape)\n",
    "\n",
    "#             # Concatenate context vector with embedded token input\n",
    "#             input_gru = torch.cat((embedded, context), dim=2)\n",
    "#             print(input_gru.shape)\n",
    "#             # Ensure the hidden state is 3D for the GRU\n",
    "#             if self.bidirectional:\n",
    "#                 decoder_hidden = decoder_hidden.unsqueeze(0).repeat(self.num_layers * 2, 1, 1)\n",
    "#             else:\n",
    "#                 decoder_hidden = decoder_hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n",
    "#             print(input_gru.shape, decoder_hidden.shape)\n",
    "#             # Pass through GRU\n",
    "#             output, decoder_hidden = self.gru(input_gru, decoder_hidden)\n",
    "#             print(f\"After GRU, decoder_hidden shape: {decoder_hidden.shape}\")  # Track shape\n",
    "\n",
    "#             # After GRU, recover `decoder_hidden` to 2D (for attention)\n",
    "#             if self.bidirectional:\n",
    "#                 # For bidirectional GRU, take the last two hidden states, concatenate them, and flatten\n",
    "#                 decoder_hidden = decoder_hidden[-2:, :, :].transpose(0, 1).contiguous().view(batch_size, -1)\n",
    "#             else:\n",
    "#                 # For unidirectional GRU, just take the last hidden state\n",
    "#                 decoder_hidden = decoder_hidden[-1, :, :]\n",
    "\n",
    "#             print(f\"Recovered decoder_hidden shape for attention: {decoder_hidden.shape}\")\n",
    "\n",
    "#             # Apply FC layer to get the output logits (adjusted for bidirectional GRU)\n",
    "#             output = self.out(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "\n",
    "#             # Apply FC layer to decoder_hidden\n",
    "#             decoder_hidden = self.fc(decoder_hidden)\n",
    "#             print(f\"After FC layer, decoder_hidden shape: {decoder_hidden.shape}\")\n",
    "\n",
    "#             # Store output and attention weights for each timestep\n",
    "#             decoder_outputs.append(output)\n",
    "#             attentions.append(attn_weights)\n",
    "\n",
    "#             if target_tensor is not None:\n",
    "#                 # Teacher forcing: Use true token as the next input\n",
    "#                 decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "#             else:\n",
    "#                 # Use predicted token as the next input (inference)\n",
    "#                 _, topi = output.topk(1)\n",
    "#                 decoder_input = topi.squeeze(-1).unsqueeze(1).detach()  # Unsqueeze to get shape [batch_size, 1]\n",
    "\n",
    "#         # Concatenate decoder outputs for all timesteps\n",
    "#         decoder_outputs = torch.stack(decoder_outputs, dim=1)  # (batch_size, MAX_LENGTH, vocab_size)\n",
    "#         attentions = torch.stack(attentions, dim=1)  # (batch_size, MAX_LENGTH, seq_len)\n",
    "\n",
    "#         return decoder_outputs, decoder_hidden, attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d593dde2",
   "metadata": {
    "id": "4c328eb1-7c5f-46d9-bbad-e990d5acb491",
    "papermill": {
     "duration": 0.025245,
     "end_time": "2025-04-05T01:13:45.768724",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.743479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAttnDecoderGRU\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size, vocab_size, attention_type, dropout_p=\u001b[32m0.1\u001b[39m, num_layers=\u001b[32m2\u001b[39m, bidirectional=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28msuper\u001b[39m(AttnDecoderGRU, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class AttnDecoderGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, attention_type, dropout_p=0.1, num_layers=2, bidirectional=True):\n",
    "        super(AttnDecoderGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        # Embedding layer for target tokens\n",
    "        # This will map token indices to dense vectors of size `hidden_size`\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        # Choose the attention mechanism (Bahdanau or Luong)\n",
    "        if attention_type == 'Luong':\n",
    "            self.attention = LuongAttention(hidden_size)\n",
    "        elif attention_type == 'Bahdanau':\n",
    "            self.attention = BahdanauAttention(hidden_size)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown attention type\")\n",
    "\n",
    "        # GRU layer for generating output sequence\n",
    "        # Input size to the GRU is hidden_size + context_size\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout_p, bidirectional=bidirectional)\n",
    "\n",
    "        # Linear layer to project GRU output to vocab size\n",
    "        # If bidirectional GRU, we need to use hidden_size * 2 because GRU output will have twice the hidden size\n",
    "        self.out = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, vocab_size)\n",
    "\n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Fully connected layer for adjusting decoder hidden state dimension (optional)\n",
    "        self.fc = nn.Linear(hidden_size * 2 if bidirectional else hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, decoder_input, decoder_hidden, encoder_outputs, target_tensor=None, device='cuda'):\n",
    "\n",
    "        decoder_input = decoder_input.to(device)\n",
    "        decoder_hidden = decoder_hidden.to(device)\n",
    "        encoder_outputs = encoder_outputs.to(device)\n",
    "\n",
    "        batch_size = encoder_outputs.size(0)  # Get batch size from encoder outputs\n",
    "\n",
    "        # Store outputs and attention weights for visualization or further processing\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        # Initialize the first decoder input (SOS token)\n",
    "        decoder_input = torch.full((batch_size, 1), SOS_token, dtype=torch.long, device=device)\n",
    "\n",
    "        for i in range(MAX_LENGTH):  # Iterate over all timesteps (max length of output)\n",
    "\n",
    "            # Compute the context vector and attention weights\n",
    "            context, attn_weights = self.attention(encoder_outputs, decoder_hidden)\n",
    "\n",
    "            # Embed the current decoder input token (converted to hidden_size dimension)\n",
    "            embedded = self.embedding(decoder_input)\n",
    "            embedded = self.dropout(embedded)  # Apply dropout for regularization\n",
    "\n",
    "            # Ensure context has the correct shape for concatenation\n",
    "            context = context.unsqueeze(1)  # Add sequence dimension to context: (batch_size, 1, hidden_size * 2)\n",
    "\n",
    "            # Concatenate context vector with embedded token input\n",
    "            input_gru = torch.cat((embedded, context), dim=2)  # Concatenate along the feature dimension\n",
    "\n",
    "            # Ensure the hidden state is 3D for the GRU (num_layers, batch_size, hidden_size)\n",
    "            if self.bidirectional:\n",
    "                decoder_hidden = decoder_hidden.unsqueeze(0).repeat(self.num_layers * 2, 1, 1)  # For bidirectional\n",
    "            else:\n",
    "                decoder_hidden = decoder_hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)  # For unidirectional\n",
    "\n",
    "            # Pass through the GRU layer\n",
    "            output, decoder_hidden = self.gru(input_gru, decoder_hidden)\n",
    "\n",
    "            # After GRU, recover `decoder_hidden` to 2D for attention (batch_size, hidden_size * 2 if bidirectional)\n",
    "            if self.bidirectional:\n",
    "                # For bidirectional GRU, concatenate the last two hidden states (forward and backward)\n",
    "                decoder_hidden = decoder_hidden[-2:, :, :].transpose(0, 1).contiguous().view(batch_size, -1)\n",
    "            else:\n",
    "                # For unidirectional GRU, just take the last hidden state\n",
    "                decoder_hidden = decoder_hidden[-1, :, :]\n",
    "\n",
    "            # Apply FC layer to adjust the decoder hidden state (optional)\n",
    "            decoder_hidden = self.fc(decoder_hidden)\n",
    "\n",
    "            # Apply output layer (projection to vocab size)\n",
    "            output = self.out(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "\n",
    "            # Store output and attention weights for each timestep\n",
    "            decoder_outputs.append(output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            # Handle teacher forcing: Use true token as the next input during training\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                # In inference mode: Use predicted token as the next input\n",
    "                _, topi = output.topk(1)  # Get top predicted token\n",
    "                decoder_input = topi.squeeze(-1).unsqueeze(1).detach()  # Unsqueeze to get shape [batch_size, 1]\n",
    "\n",
    "        # Concatenate decoder outputs for all timesteps\n",
    "        decoder_outputs = torch.stack(decoder_outputs, dim=1)  # (batch_size, MAX_LENGTH, vocab_size)\n",
    "        attentions = torch.stack(attentions, dim=1)  # (batch_size, MAX_LENGTH, seq_len)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d76d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:45.796366Z",
     "iopub.status.busy": "2025-04-05T01:13:45.796118Z",
     "iopub.status.idle": "2025-04-05T01:13:46.090264Z",
     "shell.execute_reply": "2025-04-05T01:13:46.089326Z"
    },
    "id": "6f9aea1b-aa53-4246-8fbb-2f6260a38b5a",
    "outputId": "da0ae3fa-cad5-4ebe-ff80-33aacab8f8ce",
    "papermill": {
     "duration": 0.309653,
     "end_time": "2025-04-05T01:13:46.091721",
     "exception": false,
     "start_time": "2025-04-05T01:13:45.782068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AttnDecoderGRU(\n",
       "   (embedding): Embedding(30522, 512)\n",
       "   (attention): LuongAttention(\n",
       "     (attn): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (gru): GRU(1024, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "   (out): Linear(in_features=512, out_features=30522, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       " ),\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = AttnDecoderGRU(hidden_dim, vocab_size, \"Luong\")\n",
    "decoder, next(decoder.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c2a77a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.120135Z",
     "iopub.status.busy": "2025-04-05T01:13:46.119873Z",
     "iopub.status.idle": "2025-04-05T01:13:46.170677Z",
     "shell.execute_reply": "2025-04-05T01:13:46.169958Z"
    },
    "id": "ktpaOvNdPN8K",
    "outputId": "e1689300-303f-4181-c25a-a066fd6897e6",
    "papermill": {
     "duration": 0.066047,
     "end_time": "2025-04-05T01:13:46.171867",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.105820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AttnDecoderGRU(\n",
       "   (embedding): Embedding(30522, 512)\n",
       "   (attention): LuongAttention(\n",
       "     (attn): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (gru): GRU(1024, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "   (out): Linear(in_features=512, out_features=30522, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       " ),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.to(device), next(decoder.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62be6ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.199878Z",
     "iopub.status.busy": "2025-04-05T01:13:46.199632Z",
     "iopub.status.idle": "2025-04-05T01:13:46.202534Z",
     "shell.execute_reply": "2025-04-05T01:13:46.201853Z"
    },
    "id": "90adf0d4-d798-440a-b9c5-85ce667e00c4",
    "papermill": {
     "duration": 0.01813,
     "end_time": "2025-04-05T01:13:46.203693",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.185563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input = batch['source_input_ids'].to(device)\n",
    "# decoder_outputs, decoder_hidden, attentions = decoder(input, hidden, gru_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a639ccc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.232172Z",
     "iopub.status.busy": "2025-04-05T01:13:46.231959Z",
     "iopub.status.idle": "2025-04-05T01:13:46.234887Z",
     "shell.execute_reply": "2025-04-05T01:13:46.234284Z"
    },
    "id": "330d0c91-7039-4a13-b868-c5e615b8c1fb",
    "papermill": {
     "duration": 0.018989,
     "end_time": "2025-04-05T01:13:46.236047",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.217058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decoder_outputs.shape, decoder_hidden.shape, attentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef80d87a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.263570Z",
     "iopub.status.busy": "2025-04-05T01:13:46.263351Z",
     "iopub.status.idle": "2025-04-05T01:13:46.266406Z",
     "shell.execute_reply": "2025-04-05T01:13:46.265771Z"
    },
    "id": "8f0be325-568f-454e-be57-3574afd7bd19",
    "papermill": {
     "duration": 0.017908,
     "end_time": "2025-04-05T01:13:46.267520",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.249612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Seq2Seq(nn.Module):\n",
    "#     def __init__(self, encoder, decoder, device):\n",
    "#         super(Seq2Seq, self).__init__()\n",
    "\n",
    "#         self.encoder = encoder\n",
    "#         self.decoder = decoder\n",
    "#         self.device = device\n",
    "\n",
    "#     def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "#         # Encoder step: Pass the source sequence through the encoder\n",
    "#         encoder_outputs, hidden = self.encoder(source)\n",
    "\n",
    "#         # Decoder step: Initialize decoder input (SOS token)\n",
    "#         input = target[:, 0]\n",
    "#         outputs = []\n",
    "\n",
    "#         for t in range(1, target.size(1)):  # Iterate over each time step in the target sequence\n",
    "#             # Pass encoder outputs and hidden state to the decoder\n",
    "#             decoder_output, hidden, attentions_timestep = self.decoder(input, hidden, encoder_outputs)\n",
    "\n",
    "#             outputs.append(decoder_output)\n",
    "#             input = target[:, t] if torch.rand(1).item() < teacher_forcing_ratio else decoder_output.argmax(dim=2)\n",
    "\n",
    "#         # Concatenate all outputs for the full sequence\n",
    "#         outputs = torch.cat(outputs, dim=1)\n",
    "#         return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "011a2738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.295117Z",
     "iopub.status.busy": "2025-04-05T01:13:46.294897Z",
     "iopub.status.idle": "2025-04-05T01:13:46.300554Z",
     "shell.execute_reply": "2025-04-05T01:13:46.299906Z"
    },
    "id": "NmwX8bWjgnbN",
    "papermill": {
     "duration": 0.020872,
     "end_time": "2025-04-05T01:13:46.301695",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.280823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        # Encoder step: Pass the source sequence through the encoder\n",
    "        encoder_outputs, hidden = self.encoder(source)\n",
    "\n",
    "        # Decoder step: Initialize decoder input (SOS token)\n",
    "        input = target[:, 0]  # Starting with the first token from the target sequence\n",
    "        batch_size = source.size(0)\n",
    "        trg_len = target.size(1)\n",
    "        output_dim = vocab_size\n",
    "\n",
    "        # Initialize an empty tensor to hold the outputs for each time step\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "\n",
    "        for t in range(1, trg_len):  # Iterate over each time step in the target sequence\n",
    "            # Pass encoder outputs and hidden state to the decoder\n",
    "            decoder_output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "\n",
    "            # Since decoder_output is already of shape [batch_size, trg_len, output_dim],\n",
    "            # we can assign it to the outputs tensor without any additional steps.\n",
    "            outputs[:, t, :] = decoder_output[:, t, :]  # Assigning one token's output at a time\n",
    "\n",
    "            # Decide whether to use teacher forcing or not\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = decoder_output.argmax(dim=2)  # Get the most likely next token\n",
    "\n",
    "            # Use teacher forcing or predicted token\n",
    "            input = target[:, t] if teacher_force else top1.squeeze(1)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "864f2293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.328754Z",
     "iopub.status.busy": "2025-04-05T01:13:46.328538Z",
     "iopub.status.idle": "2025-04-05T01:13:46.333220Z",
     "shell.execute_reply": "2025-04-05T01:13:46.332603Z"
    },
    "id": "33bd587d-31a7-41bc-bcaf-a16f6ee9f744",
    "outputId": "004310be-3cc9-47d5-8995-7180a2b865b5",
    "papermill": {
     "duration": 0.019599,
     "end_time": "2025-04-05T01:13:46.334441",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.314842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq2Seq(\n",
       "   (encoder): EncoderGRU(\n",
       "     (embedding): Embedding(30522, 768)\n",
       "     (gru): GRU(768, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   )\n",
       "   (decoder): AttnDecoderGRU(\n",
       "     (embedding): Embedding(30522, 512)\n",
       "     (attention): LuongAttention(\n",
       "       (attn): Linear(in_features=512, out_features=512, bias=True)\n",
       "     )\n",
       "     (gru): GRU(1024, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "     (out): Linear(in_features=512, out_features=30522, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       " ),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(encoder, decoder, device)\n",
    "seq2seq, next(seq2seq.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9099238e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.361675Z",
     "iopub.status.busy": "2025-04-05T01:13:46.361470Z",
     "iopub.status.idle": "2025-04-05T01:13:46.369020Z",
     "shell.execute_reply": "2025-04-05T01:13:46.368343Z"
    },
    "id": "7N_9niNjPcNJ",
    "outputId": "60fad355-8cce-4a04-aace-dee5e7c05250",
    "papermill": {
     "duration": 0.022515,
     "end_time": "2025-04-05T01:13:46.370269",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.347754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Seq2Seq(\n",
       "   (encoder): EncoderGRU(\n",
       "     (embedding): Embedding(30522, 768)\n",
       "     (gru): GRU(768, 512, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   )\n",
       "   (decoder): AttnDecoderGRU(\n",
       "     (embedding): Embedding(30522, 512)\n",
       "     (attention): LuongAttention(\n",
       "       (attn): Linear(in_features=512, out_features=512, bias=True)\n",
       "     )\n",
       "     (gru): GRU(1024, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "     (out): Linear(in_features=512, out_features=30522, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       " ),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.to(device), next(seq2seq.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df7d41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.397878Z",
     "iopub.status.busy": "2025-04-05T01:13:46.397668Z",
     "iopub.status.idle": "2025-04-05T01:13:46.400301Z",
     "shell.execute_reply": "2025-04-05T01:13:46.399719Z"
    },
    "id": "R6y9vBCzPYhJ",
    "papermill": {
     "duration": 0.017738,
     "end_time": "2025-04-05T01:13:46.401558",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.383820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outputs = seq2seq(batch['source_input_ids'].to('cuda'),  batch['target_input_ids'].to('cuda'), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1c585e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.429330Z",
     "iopub.status.busy": "2025-04-05T01:13:46.429059Z",
     "iopub.status.idle": "2025-04-05T01:13:46.431843Z",
     "shell.execute_reply": "2025-04-05T01:13:46.431228Z"
    },
    "id": "b7bfe69f-de83-4218-93e5-5561a1c7d302",
    "papermill": {
     "duration": 0.017951,
     "end_time": "2025-04-05T01:13:46.433006",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.415055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e7492e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.460773Z",
     "iopub.status.busy": "2025-04-05T01:13:46.460540Z",
     "iopub.status.idle": "2025-04-05T01:13:46.464104Z",
     "shell.execute_reply": "2025-04-05T01:13:46.463508Z"
    },
    "id": "72dadc14-c5f5-4caa-8485-bc334ec75181",
    "papermill": {
     "duration": 0.018905,
     "end_time": "2025-04-05T01:13:46.465367",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.446462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bleu(predictions, targets):\n",
    "    # If predictions and targets are numpy arrays, ensure you iterate over each sequence.\n",
    "    # Convert numpy arrays to lists of strings if needed.\n",
    "    pred = [[str(token).split()] for token in predictions]  # Ensure token is a string before applying split\n",
    "    ref = [[str(token).split()] for token in targets]       # Same for targets\n",
    "    return corpus_bleu(ref, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4468ecc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.493552Z",
     "iopub.status.busy": "2025-04-05T01:13:46.493318Z",
     "iopub.status.idle": "2025-04-05T01:13:46.497976Z",
     "shell.execute_reply": "2025-04-05T01:13:46.497339Z"
    },
    "id": "ca4f5209-7108-40e7-ac7d-e615f849cdfc",
    "papermill": {
     "duration": 0.020193,
     "end_time": "2025-04-05T01:13:46.499152",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.478959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metrics(train_losses, val_losses, bleu_scores):\n",
    "    epochs = len(train_losses)\n",
    "\n",
    "    # Plot Train Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(epochs), train_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(range(epochs), val_losses, label='Validation Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot BLEU score over epochs\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(epochs), bleu_scores, label='Validation BLEU Score', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('BLEU Score')\n",
    "    plt.title('Validation BLEU Score over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a54dec66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.527364Z",
     "iopub.status.busy": "2025-04-05T01:13:46.527102Z",
     "iopub.status.idle": "2025-04-05T01:13:46.530807Z",
     "shell.execute_reply": "2025-04-05T01:13:46.530175Z"
    },
    "papermill": {
     "duration": 0.019019,
     "end_time": "2025-04-05T01:13:46.531998",
     "exception": false,
     "start_time": "2025-04-05T01:13:46.512979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the path to save the model\n",
    "MODEL_PATH = 'full_seq2seq_model.pth'\n",
    "\n",
    "def save_full_model(model, optimizer, epoch, loss, model_path=MODEL_PATH):\n",
    "    # Save the entire model, optimizer, epoch, and loss\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model': model,  # Save the entire model including architecture and weights\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, model_path)\n",
    "    print(f\"Full model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad48334e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T01:13:46.559837Z",
     "iopub.status.busy": "2025-04-05T01:13:46.559619Z",
     "iopub.status.idle": "2025-04-05T08:06:14.507654Z",
     "shell.execute_reply": "2025-04-05T08:06:14.506399Z"
    },
    "id": "5f21924b-5671-4d2f-b129-4b3c6caa49a6",
    "outputId": "3afd313b-1c83-469c-cdc2-008c5830f020",
    "papermill": {
     "duration": 24747.96334,
     "end_time": "2025-04-05T08:06:14.508881",
     "exception": true,
     "start_time": "2025-04-05T01:13:46.545541",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing: 100%|██████████| 2084/2084 [6:51:14<00:00, 11.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model saved to full_seq2seq_model.pth\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-abd3dfa575a9>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbleu_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-abd3dfa575a9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, epochs, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Calculate BLEU score for the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mval_bleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mbleu_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_bleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-040d68d2b194>\u001b[0m in \u001b[0;36mcompute_bleu\u001b[0;34m(predictions, targets)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Ensure token is a string before applying split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m       \u001b[0;31m# Same for targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mcorpus_bleu\u001b[0;34m(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh, emulate_multibleu)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# denominator for the corpus-level modified precision.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mp_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mp_numerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mp_denominators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py\u001b[0m in \u001b[0;36mmodified_precision\u001b[0;34m(references, hypothesis, n)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# Extracts all ngrams in hypothesis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;31m# Set an empty Counter if hypothesis is empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;31m# Extract a union of references' counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;31m## max_counts = reduce(or_, [Counter(ngrams(ref, n)) for ref in references])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m         '''\n\u001b[1;32m    576\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "MAX_LENGTH = 50\n",
    "PAD_token = 0\n",
    "\n",
    "train_loader = get_dataloader(train)\n",
    "val_loader = get_dataloader(validation)\n",
    "test_loader = get_dataloader(test)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=10, teacher_forcing_ratio=0.5, device='cuda'):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    bleu_scores = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "\n",
    "        # Train step\n",
    "        for batch in tqdm(train_loader, desc=\"Batch processing\"):\n",
    "            source = batch['source_input_ids'].to(device)\n",
    "            target = batch['target_input_ids'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output  = model(source, target, teacher_forcing_ratio)\n",
    "            # Compute loss\n",
    "            loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Average training loss for this epoch\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validate step\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                source = batch['source_input_ids'].to(device)\n",
    "                target = batch['target_input_ids'].to(device)\n",
    "\n",
    "                # Forward pass (without teacher forcing)\n",
    "                output = model(source, target, teacher_forcing_ratio=0)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(output.view(-1, output.size(-1)), target.view(-1))\n",
    "\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "                # Store predictions and targets for BLEU calculation\n",
    "                pred = output.argmax(dim=-1)\n",
    "                val_predictions.extend(pred.cpu().numpy())\n",
    "                val_targets.extend(target.cpu().numpy())\n",
    "\n",
    "        # Average validation loss for this epoch\n",
    "        val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        save_full_model(model, optimizer, epoch, train_loss)\n",
    "\n",
    "        # Calculate BLEU score for the validation set\n",
    "        val_bleu_score = compute_bleu(val_predictions, val_targets)\n",
    "        bleu_scores.append(val_bleu_score)\n",
    "\n",
    "        # Print results for this epoch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val BLEU: {val_bleu_score:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "    return train_losses, val_losses, bleu_scores\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
    "\n",
    "\n",
    "train_losses, val_losses, bleu_scores = train_model(seq2seq, train_loader, val_loader, optimizer, criterion, epochs=10, teacher_forcing_ratio=0.5, device=device)\n",
    "\n",
    "plot_metrics(train_losses, val_losses, bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25a41f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ce092",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.927Z"
    },
    "id": "7769c873-272d-4c08-809e-567fc1703cc1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define the path to save your model\n",
    "MODEL_PATH = \"model.pth\"  # You can choose any path\n",
    "\n",
    "# Save the model's state_dict and optimizer's state_dict (if needed)\n",
    "def save_model(model, optimizer, epoch, loss, model_path=MODEL_PATH):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270cbed7",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.927Z"
    },
    "id": "O_8L2x16mMdA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model(model, optimizer=None, model_path=MODEL_PATH):\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    # Load the model's state_dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # If you're using an optimizer and want to resume training, load the optimizer state_dict\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # Optionally return the epoch and loss (if you want to resume training)\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    return model, optimizer, epoch, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997427d1",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.927Z"
    },
    "id": "5c693e7c-744c-46d6-94c0-96d6f5cb0a31",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set after training\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = []\n",
    "    test_targets = []\n",
    "\n",
    "    for batch in test_loader:\n",
    "        source = batch['source_input_ids'].to(device)\n",
    "        target = batch['target_input_ids'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output, _ = model(source, target, teacher_forcing_ratio=0)  # no teacher forcing for inference\n",
    "\n",
    "        # Collect predictions and targets\n",
    "        pred = output.argmax(dim=-1)\n",
    "        test_predictions.extend(pred.cpu().numpy())\n",
    "        test_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    # Calculate BLEU score on the test set\n",
    "    test_bleu_score = compute_bleu(test_predictions, test_targets)\n",
    "    print(f\"Test BLEU: {test_bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77924a",
   "metadata": {
    "id": "3a76a9a2-92b1-46fb-b054-67d20454a90a",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### SentencePiece Tokenizer (Using MarianMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b047dfc",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.927Z"
    },
    "id": "87ec983f-6583-4d1c-b849-90407c85f696",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import MarianTokenizer\n",
    "\n",
    "# # Load the pre-trained SentencePiece tokenizer for English-Vietnamese\n",
    "# tokenizer_sp = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-vi\")\n",
    "\n",
    "# # Example text to tokenize\n",
    "# text = \"Hello, how are you doing?\"\n",
    "\n",
    "# # Tokenizing the text\n",
    "# tokens_sp = tokenizer_sp.tokenize(text)\n",
    "# print(\"SentencePiece Tokenization:\", tokens_sp)\n",
    "\n",
    "# # Converting tokens to input IDs (numerical representation)\n",
    "# input_ids_sp = tokenizer_sp.encode(text)\n",
    "# print(\"Input IDs (SentencePiece):\", input_ids_sp)\n",
    "\n",
    "# # Decoding back to the original text\n",
    "# decoded_text_sp = tokenizer_sp.decode(input_ids_sp)\n",
    "# print(\"Decoded text (SentencePiece):\", decoded_text_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad68d9",
   "metadata": {
    "id": "fa21585b-8695-407b-9e9f-a522427640e6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Byte Pair Encoding (BPE) Tokenizer (Using GPT-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3662e",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.928Z"
    },
    "id": "d35c9bbf-ae5e-4615-b36c-dd6b1d8ddc46",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer\n",
    "\n",
    "# # Load the pre-trained BPE tokenizer (GPT-2)\n",
    "# tokenizer_bpe = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Example text to tokenize\n",
    "# text = \"Hello, how are you doing?\"\n",
    "\n",
    "# # Tokenizing the text\n",
    "# tokens_bpe = tokenizer_bpe.tokenize(text)\n",
    "# print(\"BPE Tokenization:\", tokens_bpe)\n",
    "\n",
    "# # Converting tokens to input IDs (numerical representation)\n",
    "# input_ids_bpe = tokenizer_bpe.encode(text)\n",
    "# print(\"Input IDs (BPE):\", input_ids_bpe)\n",
    "\n",
    "# # Decoding back to the original text\n",
    "# decoded_text_bpe = tokenizer_bpe.decode(input_ids_bpe)\n",
    "# print(\"Decoded text (BPE):\", decoded_text_bpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786315ba",
   "metadata": {
    "id": "cb2bd9d6-8662-44b4-b9bb-6bb3d28dbf95",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### WordPiece Tokenizer (Using BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f068f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-04T16:43:07.928Z"
    },
    "id": "686f6fc4-5931-4d3f-b120-212b9409967c",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer\n",
    "\n",
    "# # Load the pre-trained WordPiece tokenizer (BERT)\n",
    "# tokenizer_wp = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # Example text to tokenize\n",
    "# text = \"Hello, how are you doing?\"\n",
    "\n",
    "# # Tokenizing the text\n",
    "# tokens_wp = tokenizer_wp.tokenize(text)\n",
    "# print(\"WordPiece Tokenization:\", tokens_wp)\n",
    "\n",
    "# # Converting tokens to input IDs (numerical representation)\n",
    "# input_ids_wp = tokenizer_wp.encode(text)\n",
    "# print(\"Input IDs (WordPiece):\", input_ids_wp)\n",
    "\n",
    "# # Decoding back to the original text\n",
    "# decoded_text_wp = tokenizer_wp.decode(input_ids_wp)\n",
    "# print(\"Decoded text (WordPiece):\", decoded_text_wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab3727",
   "metadata": {
    "id": "53a6aedf-c41d-4783-8896-0602bc395d96",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac54c8",
   "metadata": {
    "id": "544eee5b-8ae3-460e-8f19-30c5b13d5edf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238b59e",
   "metadata": {
    "id": "f4ab9618-606a-4e8d-af16-f27f80a49581",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7050326,
     "sourceId": 11277334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (py_3.11)",
   "language": "python",
   "name": "py_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24784.003425,
   "end_time": "2025-04-05T08:06:18.008800",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-05T01:13:14.005375",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00a53cde13c54995b3b5906184f19da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07b9cb668bb44745b0d16acfdb460ac4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0eafba9fe9b545b7b0ea14be82fc425a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1471b565d9c0425089737f353b6ae1a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_595d45d37a6e48c08b138b6cae553a02",
       "placeholder": "​",
       "style": "IPY_MODEL_80b41c409f7b4f8f978f9221a0eea40b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "1857cbda7cf44f1195bd8516ae54a10e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "187ad0e6973a463684ae00f767714fbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3303fe9357ad46da8a4d17bc88594bc4",
       "placeholder": "​",
       "style": "IPY_MODEL_e45f6d83a6e44e1aad46d9d411cca4c2",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 54.0kB/s]"
      }
     },
     "1a38dbceec5943f6b65d6526d59afec3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b1fa0d5c6cd4971a70b2622ece4bc40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "235a182b745346babc146dfadb0f594c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_29d3f5a381544841bf96034cdbc7df6d",
       "max": 570,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c34036b0dabc45f7a643d0aeaedab859",
       "tabbable": null,
       "tooltip": null,
       "value": 570
      }
     },
     "2957e77fbc384887a7030e0a468f4795": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "299b105e54e84a95847a32da935567e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1471b565d9c0425089737f353b6ae1a8",
        "IPY_MODEL_a23d29460d094562aeb438e61ae0c002",
        "IPY_MODEL_93e9a05b56c04a669757de5d3881f382"
       ],
       "layout": "IPY_MODEL_2e02fe6238674e1898b3cacc5f533a47",
       "tabbable": null,
       "tooltip": null
      }
     },
     "29d3f5a381544841bf96034cdbc7df6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e02fe6238674e1898b3cacc5f533a47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3303fe9357ad46da8a4d17bc88594bc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35ff2c27eeb94bb58dac0b33f4b3dcbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "36a6705bac124e099bd2fc737b4ec738": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a0790e9060714401aba8cdd5d1dff6c3",
        "IPY_MODEL_235a182b745346babc146dfadb0f594c",
        "IPY_MODEL_187ad0e6973a463684ae00f767714fbd"
       ],
       "layout": "IPY_MODEL_c51ce8c203394b6aa56a662f61041d85",
       "tabbable": null,
       "tooltip": null
      }
     },
     "37f37f75e2ab4e6c91497b9688556a80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7823372b0cc44d9cb4fd8e01b03025b1",
       "placeholder": "​",
       "style": "IPY_MODEL_e1d82d7a92254784a1fe81a4279070fb",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.47kB/s]"
      }
     },
     "3854bab0eeb64150b6d423719f81ce79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ac85e86f36b438a8a1aaf86364a46a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ea8aedd316b47d7872015c4b904f013": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "405545fe4efc4034a751ff5cfc364409": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a38dbceec5943f6b65d6526d59afec3",
       "max": 466062,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bb1d35d4cd0145cdba08fb172e4c0e0b",
       "tabbable": null,
       "tooltip": null,
       "value": 466062
      }
     },
     "43b24230ebeb432bb28add3c5ce9d9fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45edc6e112274c489b1b1f97c15f72ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "533db5ff0b534fc8988500c05281e7f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "595d45d37a6e48c08b138b6cae553a02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "692312defc3e47bea5f44981010bd7fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f80d2e082ec43b78c6472c3781b33d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7823372b0cc44d9cb4fd8e01b03025b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e20640e051a4665b1b89e4ec47262f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "80b41c409f7b4f8f978f9221a0eea40b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "825728a9baf54fe7a163ac5008c3dd65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dacb3e49e70a42c68e82bd937773d382",
       "max": 48,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ea8aedd316b47d7872015c4b904f013",
       "tabbable": null,
       "tooltip": null,
       "value": 48
      }
     },
     "8b32ffbf490442da92bb82409afebd8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2d01e07fbfe4aa1aa0d087b3c4b149f",
        "IPY_MODEL_b6c1677b538240be83c5d08fe5d3d402",
        "IPY_MODEL_bf3487d5d37f4c79993009c09875d6a6"
       ],
       "layout": "IPY_MODEL_f3636035fada406c84972c586910712c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8f94c723367947f5b71501373f22e172": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b05b6061594f47629fb62bd96399c46a",
       "placeholder": "​",
       "style": "IPY_MODEL_07b9cb668bb44745b0d16acfdb460ac4",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 26.6MB/s]"
      }
     },
     "90214b6a37cc4c72b19ee3cc3cab8661": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93e9a05b56c04a669757de5d3881f382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_692312defc3e47bea5f44981010bd7fa",
       "placeholder": "​",
       "style": "IPY_MODEL_0eafba9fe9b545b7b0ea14be82fc425a",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 8.35MB/s]"
      }
     },
     "958645faec544b798e0129721f407ef7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "962e181cfe6943998a91fbec0f009079": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a0790e9060714401aba8cdd5d1dff6c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_958645faec544b798e0129721f407ef7",
       "placeholder": "​",
       "style": "IPY_MODEL_45edc6e112274c489b1b1f97c15f72ea",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "a23d29460d094562aeb438e61ae0c002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ac85e86f36b438a8a1aaf86364a46a5",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7e20640e051a4665b1b89e4ec47262f7",
       "tabbable": null,
       "tooltip": null,
       "value": 231508
      }
     },
     "af23869ef4724813abafa197ecf284dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90214b6a37cc4c72b19ee3cc3cab8661",
       "placeholder": "​",
       "style": "IPY_MODEL_2957e77fbc384887a7030e0a468f4795",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "b05b6061594f47629fb62bd96399c46a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6c1677b538240be83c5d08fe5d3d402": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6f80d2e082ec43b78c6472c3781b33d0",
       "max": 440449768,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_962e181cfe6943998a91fbec0f009079",
       "tabbable": null,
       "tooltip": null,
       "value": 440449768
      }
     },
     "bb1d35d4cd0145cdba08fb172e4c0e0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bf3487d5d37f4c79993009c09875d6a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_533db5ff0b534fc8988500c05281e7f7",
       "placeholder": "​",
       "style": "IPY_MODEL_35ff2c27eeb94bb58dac0b33f4b3dcbc",
       "tabbable": null,
       "tooltip": null,
       "value": " 440M/440M [00:01&lt;00:00, 290MB/s]"
      }
     },
     "c34036b0dabc45f7a643d0aeaedab859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c51ce8c203394b6aa56a662f61041d85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c665a850464f45f49320374058c65fb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_af23869ef4724813abafa197ecf284dd",
        "IPY_MODEL_825728a9baf54fe7a163ac5008c3dd65",
        "IPY_MODEL_37f37f75e2ab4e6c91497b9688556a80"
       ],
       "layout": "IPY_MODEL_00a53cde13c54995b3b5906184f19da3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ca2ad90f667941848bd1c8d050561d48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc8a41f1d3ec412da375c3befa54b5cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1857cbda7cf44f1195bd8516ae54a10e",
       "placeholder": "​",
       "style": "IPY_MODEL_3854bab0eeb64150b6d423719f81ce79",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "dacb3e49e70a42c68e82bd937773d382": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df78b2c0e86041cea236171e20777275": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc8a41f1d3ec412da375c3befa54b5cc",
        "IPY_MODEL_405545fe4efc4034a751ff5cfc364409",
        "IPY_MODEL_8f94c723367947f5b71501373f22e172"
       ],
       "layout": "IPY_MODEL_43b24230ebeb432bb28add3c5ce9d9fa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e1d82d7a92254784a1fe81a4279070fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2d01e07fbfe4aa1aa0d087b3c4b149f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b1fa0d5c6cd4971a70b2622ece4bc40",
       "placeholder": "​",
       "style": "IPY_MODEL_ca2ad90f667941848bd1c8d050561d48",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "e45f6d83a6e44e1aad46d9d411cca4c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f3636035fada406c84972c586910712c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
